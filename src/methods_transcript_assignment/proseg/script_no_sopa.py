import os
import shutil
from pathlib import Path
# from tifffile import imwrite
import dask
import numpy as np
import pandas as pd
import anndata as ad
import spatialdata as sd


## VIASH START
# Note: this section is auto-generated by viash at runtime. To edit it, make changes
# in config.vsh.yaml and then run `viash config inject config.vsh.yaml`.
par = {
  'input_ist': 'resources_test/task_ist_preprocessing/mouse_brain_combined/raw_ist.zarr',
  'input_segmentation': 'resources_test/task_ist_preprocessing/mouse_brain_combined/segmentation.zarr',
  'transcripts_key': 'transcripts',
  'coordinate_system': 'global',
  'output': './temp/proseg_transcripts.zarr',

}
meta = {
  'name': 'proseg',
  'temp_dir': "/Users/habib/Projects/txsim_project/task_ist_preprocessing/temp"
}
## VIASH END

TMP_DIR = Path(meta["temp_dir"] or "/tmp")
TMP_DIR.mkdir(parents=True, exist_ok=True)

TRANSCRIPTS_CSV = TMP_DIR / "transcripts.csv"
SEGMENTATION_NPY = TMP_DIR / "segmentation.npy"
PROSEG_OUTPUT = TMP_DIR / "proseg_output.zarr"


# Read input
print('Reading input files', flush=True)
sdata = sd.read_zarr(par['input_ist'])
sdata_segm = sd.read_zarr(par['input_segmentation'])

# Check if coordinate system is available in input data
transcripts_coord_systems = sd.transformations.get_transformation(sdata[par["transcripts_key"]], get_all=True).keys()
assert par['coordinate_system'] in transcripts_coord_systems, f"Coordinate system '{par['coordinate_system']}' not found in input data."
segmentation_coord_systems = sd.transformations.get_transformation(sdata_segm["segmentation"], get_all=True).keys()
assert par['coordinate_system'] in segmentation_coord_systems, f"Coordinate system '{par['coordinate_system']}' not found in input data."

# Transform transcript coordinates to the coordinate system

print('Transforming transcripts coordinates', flush=True)
transcripts = sd.transform(sdata[par['transcripts_key']], to_coordinate_system=par['coordinate_system'])

# In case of a translation transformation of the segmentation (e.g. crop of the data), we need to adjust the transcript coordinates
trans = sd.transformations.get_transformation(sdata_segm["segmentation"], get_all=True)[par['coordinate_system']].inverse()
transcripts = sd.transform(transcripts, trans, par['coordinate_system'])

# Write transcripts to csv 
print('Writing transcripts to csv', flush=True)
transcripts_df = transcripts[['x', 'y', 'z', 'feature_name']].compute()
transcripts_df['transcript_index'] = transcripts_df.index

#add segmentation for cell_id
segmentation_image = sdata_segm["segmentation"]["scale0"].image.to_numpy()

y_coords = transcripts.y.compute().to_numpy(dtype=np.int64)
x_coords = transcripts.x.compute().to_numpy(dtype=np.int64)
transcripts_df['cell_id'] = segmentation_image[y_coords, x_coords]
#write to csv
transcripts_df.to_csv(TRANSCRIPTS_CSV)

# Write segmentation to tif
print('Writing segmentation to npy', flush=True)
np.save(SEGMENTATION_NPY, segmentation_image)

# TODO: figure out how to extract the affine transformation from the spatialdata Transform
# Run Proseg
print('Running Proseg', flush=True)
#Make sure to add a space after each line
proseg_cmd = (
    f'''proseg {TRANSCRIPTS_CSV} --x-column x --y-column y --z-column z --gene-column feature_name '''
    f'''--cell-id-column cell_id --cell-id-unassigned 0 --transcript-id-column transcript_index '''
    f'''--cellpose-masks {SEGMENTATION_NPY} '''
    f'''--cellpose-x-transform 1 0 0 '''
    f'''--cellpose-y-transform 0 1 0 '''
    f'''--output-spatialdata {PROSEG_OUTPUT} --overwrite'''

)
print("\t" + proseg_cmd, flush=True)
#TODO: UNCOMMENT THIS
os.system(proseg_cmd)


# Read Proseg output
print('Reading proseg output', flush=True)
proseg_sd = sd.read_zarr(PROSEG_OUTPUT)
proseg_transcripts = sd.transform(proseg_sd['transcripts'], to_coordinate_system=par['coordinate_system']).compute()
proseg_transcripts.set_index('transcript_id', inplace=True) #here transcript_id is the index of the original, not the transcript_id in the original
proseg_transcripts = proseg_transcripts.reindex(transcripts.index).fillna(-1)

# Add cell ids to transcripts
#NOTE: ADD 1 SINCE PROSEG STARTS COUNTING CELLS AT 0 
print('Adding cell ids to transcripts', flush=True)
cell_id_dask_series = dask.dataframe.from_dask_array(
    dask.array.from_array(
        proseg_transcripts['assignment'].values+1, chunks=tuple(sdata[par['transcripts_key']].map_partitions(len).compute())
    ), 
    index=sdata[par['transcripts_key']].index
)
sdata[par['transcripts_key']]["cell_id"] = cell_id_dask_series


# Create objects for cells table
print('Creating objects for cells table', flush=True)
#create new .obs for cells based on the segmentation output (corresponding with the transcripts 'cell_id')
unique_cells = np.unique(cell_id_dask_series)

# check if a '0' (noise/background) cell is in cell_id and remove
zero_idx = np.where(unique_cells == 0)
if len(zero_idx[0]): unique_cells=np.delete(unique_cells, zero_idx[0][0])

#transform into pandas series and check
cell_id_col = pd.Series(unique_cells, name='cell_id', index=unique_cells)
assert 0 not in cell_id_col, "Found '0' in cell_id column of assingment output cell matrix"


# Create transcripts only sdata
print('Subsetting to transcripts cell id data', flush=True)
sdata_transcripts_only = sd.SpatialData(
    points={
        "transcripts": sdata[par['transcripts_key']]
    },
    tables={
        "table": ad.AnnData(
          obs=pd.DataFrame(cell_id_col),
          var=sdata.tables["table"].var[[]]
        )
    }
)

# Write output
print('Write transcripts with cell ids', flush=True)
if os.path.exists(par["output"]):
    shutil.rmtree(par["output"])
    
sdata_transcripts_only.write(par['output'])
