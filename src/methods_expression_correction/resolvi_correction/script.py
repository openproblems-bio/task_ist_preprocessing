import anndata as ad
import scvi
import pandas as pd
import scanpy as sc
import numpy as np

## VIASH START
# Note: this section is auto-generated by viash at runtime. To edit it, make changes
# in config.vsh.yaml and then run `viash config inject config.vsh.yaml`.
par = {
  'input_spatial_with_cell_types': 'resources_test/task_ist_preprocessing/mouse_brain_combined/spatial_with_cell_types.h5ad',
  'celltype_key': 'cell_type',
  'output': 'temp/resolvi_spatial_corrected.h5ad',
  'n_hidden': 32,
  'encode_covariates': False,
  'downsample_counts': True
}
meta = {
  'name': 'resolvi_correction',
}
## VIASH END

# NOTE/TODO: for grid search:
# - n_hidden: 32 (default), 64, 128
# - encode_covariates: False(default)/True
# - downsample_counts: True(default)/False

# Optional parameter check: For this specific correction method the par['input_sc'] is required
   
# Read input
print('Reading input files', flush=True)
adata_sp = ad.read_h5ad(par['input_spatial_with_cell_types'])
adata_sp.layers["normalized_uncorrected"] = adata_sp.layers["normalized"]

print("Filter cells with <5 counts")
sc.pp.filter_cells(adata_sp, min_genes=5)

spatial_array = np.stack([adata_sp.obs['centroid_x'].values, adata_sp.obs['centroid_y'].values], axis=1)
adata_sp.obsm['X_spatial'] = spatial_array

# Apply gene efficiency correction
print('Running ResolVI', flush=True)

print('Setting up anndata', flush=True)
scvi.external.RESOLVI.setup_anndata(adata_sp, labels_key=par['celltype_key'], layer="counts")

print('Setting up model', flush=True)
supervised_resolvi = scvi.external.RESOLVI(adata_sp, semisupervised=True, 
  n_hidden = par['n_hidden'], 
  encode_covariates = par['encode_covariates'], 
  downsample_counts = par['downsample_counts'])
supervised_resolvi.train(max_epochs=100)

print('Sampling posterior (corrected)', flush=True)
samples_corr = supervised_resolvi.sample_posterior(
        model=supervised_resolvi.module.model_corrected,
        return_sites=['px_rate'],
        summary_fun={"post_sample_q50": np.median},
        num_samples=20, return_samples=False, batch_size=4000) #batch_steps was not a parameter
samples_corr = pd.DataFrame(samples_corr).T

print('Sampling posterior (residuals)', flush=True)
samples = supervised_resolvi.sample_posterior(
    model=supervised_resolvi.module.model_residuals,
    return_sites=[
        'mixture_proportions', 'mean_poisson', 'per_gene_background', 
        'per_neighbor_diffusion', 'px_r_inv' #'diffusion_mixture_proportion'
        #NOTE: set of strs important: see https://github.com/scverse/scvi-tools/issues/3252#issuecomment-3304041641
        ],
    num_samples=20, return_samples=False, batch_size=4000)
samples = pd.DataFrame(samples).T


adata_sp.obsm["X_resolVI"] = supervised_resolvi.get_latent_representation()

# TODO these 2 lines threw errors because 'obs' was not generated in samples_corr
# adata_sp.layers["generated_expression"] = scipy.sparse.csr_matrix(samples_corr.loc['post_sample_q25', 'obs'])
# adata_sp.layers["generated_expression_mean"] = scipy.sparse.csr_matrix(samples_corr.loc['post_sample_means', 'obs'])

adata_sp.layers["corrected_counts"] = adata_sp.layers['counts'].multiply((samples_corr.loc['post_sample_q50', 'px_rate'] / (
    1.0 + samples_corr.loc['post_sample_q50', 'px_rate'] + samples.loc['post_sample_means', 'mean_poisson']))).tocsr()

# Normalize the corrected counts #TODO: see NOTE below
size_factors = np.array(adata_sp.layers['counts'].sum(axis=1) / adata_sp.layers['normalized'].expm1().sum(axis=1))[:,0]
adata_sp.layers["normalized"] = adata_sp.layers['corrected_counts'].multiply(1/size_factors[:,None]).log1p().toarray()
adata_sp.layers["counts"] = adata_sp.layers['corrected_counts']
del adata_sp.layers['corrected_counts']
# NOTE: this way of normalizing is not ideal. The problem is that we would need to apply the same normalization method
# to the corrected counts again. However, the pipeline setup runs the normalization step before expression correction.
# One solution would have been to move resolVI correction after the count aggregation. However, in that case we could
# only apply the unsupervised version of resolVI since ct annotation is required. In tutorials the supervised one is recommended.
# Possible future solutions (all quite some work):
# - Add an additional compute step that runs the normalization step after expression correction in case of running resolVI.
# - Feed the output of the resolVI correction back into the normalization step (this would then also run ct annotation)
#   and it would also run the correction step again (which would be problematic and need some workaround)
# - Move resolVI correction after the count aggregation but include a generic cell type annotation step (either a workflow step
#   or an annotation within the resolVI script)

# Write output
print('Writing output', flush=True)
adata_sp.write(par['output'])
